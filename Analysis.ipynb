{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56bc7b4d",
   "metadata": {},
   "source": [
    "# Analysis of the 3D BAG metrics\n",
    "\n",
    "This noteboook contains some analysis for extracting intresting information about the metrics computed via `cityStats.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5173f355",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Let's load the LoD2.2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb61722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/alabetski/3DBAG_09/all/lod2.2.csv\")\n",
    "df = df.rename(columns={\"rectangularity_3d\": \"cuboidness_3d\", \"equivalent_prism_index_3d\": \"equivalent_cuboidness_index_3d\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ca470",
   "metadata": {},
   "source": [
    "Fix the problematic min and max vertical elongation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f8538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"min_vertical_elongation\": \"width_vertical_elongation\",  \"max_vertical_elongation\": \"depth_vertical_elongation\"})\n",
    "\n",
    "df[\"max_vertical_elongation\"] = df[[\"width_vertical_elongation\", \"depth_vertical_elongation\"]].max(axis=1)\n",
    "df[\"min_vertical_elongation\"] = df[[\"width_vertical_elongation\", \"depth_vertical_elongation\"]].min(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5e360",
   "metadata": {},
   "source": [
    "## Example buildings\n",
    "\n",
    "These are the 14 example buildings that we analyse in depth in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650475e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ids = [\n",
    "    \"NL.IMBAG.Pand.0599100000702379-0\",\n",
    "    \"NL.IMBAG.Pand.0518100001635181-0\",\n",
    "    \"NL.IMBAG.Pand.0599100000701103-0\",\n",
    "#     \"NL.IMBAG.Pand.0518100000225439-0\",\n",
    "    \"NL.IMBAG.Pand.0518100000273015-0\",\n",
    "    \"NL.IMBAG.Pand.0363100012075730-0\",\n",
    "    \"NL.IMBAG.Pand.0363100012185598-0\",\n",
    "    \"NL.IMBAG.Pand.0344100000031226-0\",\n",
    "    \"NL.IMBAG.Pand.0344100000077683-0\",\n",
    "    \"NL.IMBAG.Pand.0344100000099499-0\",\n",
    "    \"NL.IMBAG.Pand.0599100000080428-0\",\n",
    "    \"NL.IMBAG.Pand.0518100000230634-0\",\n",
    "#     \"NL.IMBAG.Pand.0518100000206625-0\",\n",
    "    \"NL.IMBAG.Pand.0518100000226316-0\",\n",
    "    \"NL.IMBAG.Pand.0518100000282020-0\",\n",
    "    \"NL.IMBAG.Pand.0599100000432858-0\",\n",
    "    \"NL.IMBAG.Pand.0629100000020777-0\",\n",
    "    \"NL.IMBAG.Pand.0363100012236081-0\",\n",
    "    \"NL.IMBAG.Pand.0518100000222277-0\"\n",
    "]\n",
    "\n",
    "df[df[\"id\"].isin(selected_ids)].to_csv(\"selected.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2429236",
   "metadata": {},
   "source": [
    "## Create spider graph for indices\n",
    "\n",
    "This code creates a spider graph of 2D or 3D indices for the given buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8c12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_random_color():\n",
    "    hexadecimal = [\"#\"+''.join([random.choice('abcdef0123456789') for i in range(6)])]\n",
    "\n",
    "# Each attribute we'll plot in the radar chart.\n",
    "labels = [col for col in df.columns if col.endswith(\"_3d\") and not col.startswith(\"exchange\")]\n",
    "\n",
    "# Number of variables we're plotting.\n",
    "num_vars = len(labels)\n",
    "\n",
    "# Split the circle into even parts and save the angles\n",
    "# so we know where to put each axis.\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "\n",
    "# The plot is a circle, so we need to \"complete the loop\"\n",
    "# and append the start value to the end.\n",
    "angles += angles[:1]\n",
    "\n",
    "# ax = plt.subplot(polar=True)\n",
    "fig, ax = plt.subplots(figsize=(8, 6), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Helper function to plot each car on the radar chart.\n",
    "def add_to_radar(car_model, color, label=None):\n",
    "    values = df.set_index(\"id\").loc[car_model][labels].tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=1, label=car_model if label is None else label)\n",
    "    ax.fill(angles, values, color=color, alpha=0.25)\n",
    "\n",
    "# Add each car to the chart.\n",
    "add_to_radar('NL.IMBAG.Pand.0344100000031226-0', get_random_color(), 'A')\n",
    "add_to_radar('NL.IMBAG.Pand.0344100000077683-0', get_random_color(), 'B')\n",
    "add_to_radar('NL.IMBAG.Pand.0344100000099499-0', get_random_color(), 'C')\n",
    "add_to_radar('NL.IMBAG.Pand.0599100000080428-0', get_random_color(), 'J')\n",
    "\n",
    "# for number, objid in enumerate(selected_ids):\n",
    "#     add_to_radar(objid, get_random_color(), chr(ord('@')+number+1))\n",
    "\n",
    "# Fix axis to go in the right order and start at 12 o'clock.\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Draw axis lines for each angle and label.\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), [col.replace(\"_\", \" \").capitalize().replace(\" index\", \"\").replace(\"2d\", \"2D\").replace(\"3d\", \"3D\") for col in labels])\n",
    "\n",
    "# Go through labels and adjust alignment based on where\n",
    "# it is in the circle.\n",
    "for label, angle in zip(ax.get_xticklabels(), angles):\n",
    "    if angle in (0, np.pi):\n",
    "        label.set_horizontalalignment('center')\n",
    "    elif 0 < angle < np.pi:\n",
    "        label.set_horizontalalignment('left')\n",
    "    else:\n",
    "        label.set_horizontalalignment('right')\n",
    "\n",
    "# Ensure radar goes from 0 to 100.\n",
    "ax.set_ylim(0, 1)\n",
    "# You can also set gridlines manually like this:\n",
    "# ax.set_rgrids([20, 40, 60, 80, 100])\n",
    "\n",
    "# Set position of y-labels (0-100) to be in the middle\n",
    "# of the first two axes.\n",
    "ax.set_rlabel_position(180 / num_vars)\n",
    "\n",
    "# Add some custom styling.\n",
    "# Change the color of the tick labels.\n",
    "ax.tick_params(colors='#222222')\n",
    "# Make the y-axis (0-100) labels smaller.\n",
    "ax.tick_params(axis='y', labelsize=8)\n",
    "# Change the color of the circular gridlines.\n",
    "ax.grid(color='#AAAAAA')\n",
    "# Change the color of the outermost gridline (the spine).\n",
    "ax.spines['polar'].set_color('#222222')\n",
    "# Change the background color inside the circle itself.\n",
    "ax.set_facecolor('#FAFAFA')\n",
    "\n",
    "# Add title.\n",
    "ax.set_title('Comparing building indices', y=1.08)\n",
    "\n",
    "# Add a legend as well.\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "# fig.savefig(\"BuildingsSpider2D.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0700855",
   "metadata": {},
   "source": [
    "# PCA and Clustering\n",
    "\n",
    "## Clean the data\n",
    "\n",
    "Clean data is:\n",
    "- No holes\n",
    "- At least 40m3\n",
    "- All indices are of value between 0 to 1.2\n",
    "\n",
    "Super-clean data is:\n",
    "- All of the above\n",
    "- They are valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4f2c4",
   "metadata": {},
   "source": [
    "All data size is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_2d = [col for col in df.columns if col.endswith(\"_2d\")] + [\"horizontal_elongation\"]\n",
    "indices_2d.remove(\"exchange_index_2d\")\n",
    "\n",
    "indices_3d = ([col for col in df.columns if col.endswith(\"_3d\")] +\n",
    "              [\"horizontal_elongation\", \"min_vertical_elongation\", \"max_vertical_elongation\"])\n",
    "indices_3d.remove(\"exchange_index_3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da76af0",
   "metadata": {},
   "source": [
    "Remove buildings with holes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048cc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = df[df[\"hole_count\"] == 0]\n",
    "len(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4651302",
   "metadata": {},
   "source": [
    "Remove buildings of less than 40m3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = clean[clean[\"actual_volume\"] > 40]\n",
    "len(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 0\n",
    "max_value = 1.2\n",
    "\n",
    "for ind in indices_2d:\n",
    "    clean = clean[(clean[ind] >= min_value) & (clean[ind] <= max_value)]\n",
    "\n",
    "for ind in indices_3d:\n",
    "    clean = clean[(clean[ind] >= min_value) & (clean[ind] <= max_value)]\n",
    "\n",
    "len(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dab9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "superclean = clean[clean[\"valid\"] == True]\n",
    "len(superclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757ee2d",
   "metadata": {},
   "source": [
    "## Find clean buildings per tile\n",
    "\n",
    "We compute the number of buildings per tile and compare clean against total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_per_tile = superclean.groupby([\"tile_id\"]).count()[[\"id\"]].merge(df.groupby([\"tile_id\"]).count()[[\"id\"]], left_index=True, right_index=True)\n",
    "buildings_per_tile[\"perc\"] = buildings_per_tile[\"id_x\"] / buildings_per_tile[\"id_y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa71178",
   "metadata": {},
   "source": [
    "These are the tiles with most buildings in the final cleaned dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10635858",
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_per_tile.sort_values([\"perc\"], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815a765",
   "metadata": {},
   "source": [
    "## Select subset\n",
    "\n",
    "We will select a subset of the data to work with. We select tile `2995` as this has a high number of cleaned buildings and a big count of buildings in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "superclean_tile = superclean[superclean[\"tile_id\"] == 2995]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd088653",
   "metadata": {},
   "source": [
    "## PCA of existing data\n",
    "\n",
    "This is a Principal Component Analysis of the data to identify the most important features in the dataset.\n",
    "\n",
    "Let's normalise first. This is a standard normalisation, by centering to the mean and spreading according to the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the subset of data to conduct the analysis with\n",
    "analysis_df = superclean\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normalise(raw_data):\n",
    "    raw_data -= np.mean(raw_data, axis=0)\n",
    "    raw_data /= np.std(raw_data, axis=0)\n",
    "    \n",
    "    return raw_data\n",
    "\n",
    "pca_data_3d = np.array(analysis_df[indices_3d])\n",
    "pca_data_3d_norm = normalise(pca_data_3d)\n",
    "\n",
    "pca_data_2d = np.array(analysis_df[indices_2d])\n",
    "pca_data_2d_norm = normalise(pca_data_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a694b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_3d = pd.DataFrame(pca_data_3d_norm, columns=indices_3d, index=analysis_df[\"id\"])\n",
    "normalised_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bfd9b8",
   "metadata": {},
   "source": [
    "### 3D PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0794ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_3d = PCA(n_components=len(indices_3d)).fit(pca_data_3d)\n",
    "pca_3d.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6227c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PC_values = np.arange(pca_3d.n_components_) + 1\n",
    "plt.plot(PC_values, pca_3d.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87596c3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variance_ratio_3d = pd.DataFrame(np.transpose(np.array([[f\"PC{i}\" for i in range(pca_3d.n_components)], pca_3d.explained_variance_ratio_])), columns=[\"PC\", \"value\"]) #.set_index(\"metric\")\n",
    "variance_ratio_3d[\"value\"] = variance_ratio_3d[\"value\"].astype(\"float\")\n",
    "\n",
    "from plotnine import *\n",
    "%matplotlib inline\n",
    "\n",
    "(ggplot(variance_ratio_3d)         # defining what data to use\n",
    " + aes(x=\"reorder(PC, value)\", y=\"value\")    # defining what variable to use\n",
    " + geom_bar(stat=\"identity\")  # defining the type of plot to use\n",
    " + coord_flip()\n",
    "#  + ggtitle(\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c10b73",
   "metadata": {},
   "source": [
    "### 2D PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_2d = PCA(n_components=len(indices_2d)).fit(pca_data_2d)\n",
    "pca_2d.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PC_values = np.arange(pca_2d.n_components_) + 1\n",
    "plt.plot(PC_values, pca_2d.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac6f63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variance_ratio_2d = pd.DataFrame(np.transpose(np.array([indices_2d, pca_2d.explained_variance_ratio_])), columns=[\"metric\", \"value\"]) #.set_index(\"metric\")\n",
    "variance_ratio_2d[\"value\"] = variance_ratio_2d[\"value\"].astype(\"float\")\n",
    "\n",
    "from plotnine import *\n",
    "%matplotlib inline\n",
    "\n",
    "(ggplot(variance_ratio_2d)         # defining what data to use\n",
    " + aes(x=\"reorder(metric, value)\", y=\"value\")    # defining what variable to use\n",
    " + geom_bar(stat=\"identity\")  # defining the type of plot to use\n",
    " + coord_flip()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18a9df",
   "metadata": {},
   "source": [
    "## [WRONG] Select the most dominant features from PCA\n",
    "* This is wrong! Don't do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dominant_indices_3d = variance_ratio_3d[variance_ratio_3d[\"value\"] > 0.02][\"metric\"]\n",
    "dominant_indices_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774917b",
   "metadata": {},
   "source": [
    "## Clustering of buildings\n",
    "\n",
    "The following code will cluster buildings based on the 3D indices (it can be easily adapted to worko with 2D or any number of attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "sample = normalised_3d.sample(200000)\n",
    "\n",
    "data = sample[indices_3d].to_numpy()\n",
    "\n",
    "pca_7n = PCA(n_components=11)\n",
    "pcs = pca_7n.fit_transform(data)\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=30, linkage=\"average\").fit(pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ceb099",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668affa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"cluster\"] = clustering.labels_\n",
    "\n",
    "sample.to_csv(\"clustering_200k_30n_11f_average.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering = pd.read_csv(\"clustering_10k_10n_allf.csv\")\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "# pcs = pca2.fit_transform(clustering.to_numpy()[:,1:-1])\n",
    "pcs = pca2.fit_transform(data)\n",
    "\n",
    "finalDf = pd.DataFrame(data = pcs, columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf[\"cluster\"] = clustering.labels_\n",
    "\n",
    "(ggplot(finalDf)         # defining what data to use\n",
    " + aes(x=\"principal component 1\", y=\"principal component 2\", color=\"factor(cluster)\")    # defining what variable to use\n",
    " + geom_point() # defining the type of plot to use\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26057175",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = normalised_3d\n",
    "\n",
    "data = sample[indices_3d].to_numpy()\n",
    "\n",
    "pca_7n = PCA(n_components=11)\n",
    "# pcs = pca2.fit_transform(clustering.to_numpy()[:,1:-1])\n",
    "pcs = pca_7n.fit_transform(data)\n",
    "\n",
    "sum(pca_7n.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e879e23",
   "metadata": {},
   "source": [
    "## Extract the construction year from CityJSON\n",
    "\n",
    "The following snippet will iterate through all CityJSON files and extract the year of construction attribute (*oorspronkelijkbouwjaar*) for all buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pandas import DataFrame\n",
    "\n",
    "# import os\n",
    "# files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "files = glob.glob(\"/home/alabetski/3DBAG_09/*.json\")\n",
    "\n",
    "data = []\n",
    "\n",
    "i = 0\n",
    "for file in tqdm(files):\n",
    "    with open(file) as stream:\n",
    "        cm = json.load(stream)\n",
    "\n",
    "        for objid in cm[\"CityObjects\"]:\n",
    "            co = cm[\"CityObjects\"][objid]\n",
    "            \n",
    "            if \"oorspronkelijkbouwjaar\" in co[\"attributes\"]:\n",
    "                data.append([objid, co[\"attributes\"][\"oorspronkelijkbouwjaar\"]])\n",
    "\n",
    "columns = [\"id\", \"oorspronkelijkbouwjaar\"]\n",
    "\n",
    "jaars = DataFrame(data, columns=columns)\n",
    "jaars.to_csv(\"jaars.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
